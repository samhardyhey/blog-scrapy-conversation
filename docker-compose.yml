version: '3.8'


x-common-env: &common-env
  ELASTICSEARCH_HOST: ${ELASTICSEARCH_HOST}
  ELASTICSEARCH_PORT: ${ELASTICSEARCH_PORT}
  ENV: ${ENV}
  API_URL: http://api:${API_PORT}

services:
  # Elasticsearch container
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "${ELASTICSEARCH_PORT}:9200"
      - "${ELASTICSEARCH_TRANSPORT_PORT}:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Scrapy container
  scrapy:
    build:
      context: .
      dockerfile: Dockerfile.scrapy
    container_name: scrapy
    volumes:
      - ./scrapy:/app
      - ./data:/data
      - ./notebooks:/notebooks
    working_dir: /app
    networks:
      - app-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      <<: *common-env
    command: ["sh", "-c", "service cron start && tail -f /logs/cron.log"]

  # API container
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: api
    ports:
      - "${API_PORT}:${API_PORT}"
    volumes:
      - ./api:/app
      - ./data:/data
    networks:
      - app-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      <<: *common-env
      API_PORT: ${API_PORT}
    command: python /app/main.py

volumes:
  elasticsearch_data:
    driver: local

networks:
  app-network:
    driver: bridge
